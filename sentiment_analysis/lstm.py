# -*- coding: utf-8 -*-
"""LSTM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LliblF_8JUgozCMXZLtt3Q7zWxidtRM-
"""


# This model was used to create the sentiment analysis model for the project. 
# after the model was created, model was saved in hdf5 format.
# import necessary libraries

import os
import numpy as np
import pandas as pd
from  keras.preprocessing.text import Tokenizer
from keras_preprocessing.sequence import pad_sequences
from  keras.models import Sequential, load_model
from  keras.layers import Dense, Embedding, LSTM, Bidirectional,Flatten, Dropout
from sklearn.model_selection import train_test_split
import re
import pickle

path = "/content/drive/MyDrive/IMDB Dataset.csv"

df = pd.read_csv(path)

check_null = df.isnull().sum()

check_null

df["review"].describe()

df["sentiment"].describe()

for review in range(len(df["review"])):
    df["review"][review]=re.sub(r'<[^<>]+>', repl=" ",string=df["review"][review]) #remove html tags
    df["review"][review]=re.sub(r'[^a-zA-Z0-9\s]', repl=" ",string=df["review"][review]) #remove special characters/whitespaces

tokenizer = Tokenizer(num_words=5000)  # unique words limit set to 5000

tokenizer

tokenizer.fit_on_texts(df['review'])

X = tokenizer.texts_to_sequences(df['review'])

X[0]

len(X[0])

# padding so that all reviews will be of length 500
X = pad_sequences(X,maxlen=500)

X[0]

len(X[0])

Y = df['sentiment']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

X_train.shape

pickle_out=open('tokenizer.pickle',"wb")
pickle.dump(tokenizer,pickle_out)
pickle_out.close()

y_train=pd.get_dummies(Y_train)
y_test=pd.get_dummies(Y_test)

y_train

vocab_size = len(tokenizer.word_index) + 1 # +1 is necessary for embedding method

vocab_size

model = Sequential()
model.add(Embedding(vocab_size, 50, input_length=500))
model.add(Bidirectional(LSTM(128)))
model.add(Dropout(0.5))
model.add(Dense(2,activation='sigmoid'))
model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

from keras.callbacks import EarlyStopping
earlyStopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)

modelTraining=model.fit(X_train, y_train,
                        batch_size=128,
                        epochs=5,
                        validation_data=[X_test, y_test],
                        callbacks=[earlyStopping])

score=model.evaluate(X_test, y_test, verbose=0)

print("Test_score = ",score[0])
print("Test_accuracy = ",score[1])

model.save('SentimentalAnalysis_LSTM.h5')

testModel=load_model('SentimentalAnalysis_LSTM.h5')

myInput="""What a good way to watch movie. The movie is very good and the acting is very good."""

myInput=re.sub(r'<[^<>]+>', repl=" ",string=myInput) #Excluding html tags
myInput=re.sub(r'[^a-zA-Z0-9\s]', repl=" ",string=myInput)

myInput

prediction=tokenizer.texts_to_sequences([myInput])
prediction=pad_sequences(prediction,maxlen=500)
model.predict(prediction)

model.predict(prediction)[0][1]

